"""
Malware Analysis Router

API endpoints for dynamic malware analysis with Frida instrumentation.
"""

import logging
from datetime import datetime
from typing import List, Optional

from fastapi import (
    APIRouter,
    Depends,
    File,
    Form,
    HTTPException,
    UploadFile,
    WebSocket,
    WebSocketDisconnect,
    status,
)
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from backend.core.auth import get_current_user
from backend.core.database import get_db
from backend.core.file_validator import sanitize_filename
from backend.models.models import (
    MalwareAnalysisSession,
    RuntimeBehavior,
    MalwareArtifact,
    User,
)
from backend.services.binary_frida_service import (
    BinaryFridaService,
    FridaConfig,
    SandboxConfig,
)
from backend.services.malware_sandbox_service import (
    MalwareSandboxService,
    SandboxPlatform,
    NetworkMode,
)
from backend.services.agentic_malware_analysis import AgenticMalwareAnalysisSystem
from backend.services.integrated_binary_analyzer import (
    IntegratedBinaryAnalyzer,
    IntegratedAnalysisConfig,
    AnalysisType,
    AnalysisComponent
)

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/malware", tags=["Malware Analysis"])

# Initialize services
frida_service = BinaryFridaService()
sandbox_service = MalwareSandboxService()
agentic_system = AgenticMalwareAnalysisSystem()
integrated_analyzer = IntegratedBinaryAnalyzer()


# ============================================================================
# Pydantic Schemas
# ============================================================================

class MalwareAnalysisCreate(BaseModel):
    """Request to create malware analysis session."""
    project_id: Optional[int] = None
    enable_api_hooks: bool = True
    enable_network_monitoring: bool = True
    enable_filesystem_monitoring: bool = True
    enable_registry_monitoring: bool = True
    enable_crypto_monitoring: bool = True
    enable_anti_evasion: bool = True
    timeout_seconds: int = Field(default=300, ge=60, le=3600)
    network_mode: str = "isolated"  # none, isolated, bridge


class MalwareSessionResponse(BaseModel):
    """Malware analysis session response."""
    id: int
    session_id: str
    binary_name: str
    binary_hash_sha256: str
    platform: str
    architecture: str
    status: str
    phase: Optional[str]
    progress: float
    is_malicious: bool
    malware_family: Optional[str]
    confidence_score: Optional[float]
    threat_score: Optional[int]
    severity: Optional[str]
    capabilities: Optional[List[str]]
    mitre_tactics: Optional[List[str]]
    mitre_techniques: Optional[List[str]]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]
    created_at: datetime
    error: Optional[str]

    class Config:
        from_attributes = True


class RuntimeBehaviorResponse(BaseModel):
    """Runtime behavior response."""
    id: int
    session_id: str
    process_name: Optional[str]
    api_calls: Optional[List[dict]]
    network_connections: Optional[List[dict]]
    dns_queries: Optional[List[dict]]
    files_read: Optional[List[dict]]
    files_written: Optional[List[dict]]
    files_deleted: Optional[List[dict]]
    registry_read: Optional[List[dict]]
    registry_written: Optional[List[dict]]
    processes_created: Optional[List[dict]]
    crypto_operations: Optional[List[dict]]
    suspicious_behaviors: Optional[List[dict]]
    mitre_techniques: Optional[List[str]]
    total_api_calls: int
    total_network_connections: int
    total_files_accessed: int
    captured_at: datetime

    class Config:
        from_attributes = True


class MalwareArtifactResponse(BaseModel):
    """Malware artifact response."""
    id: int
    session_id: str
    artifact_type: str
    artifact_name: str
    artifact_size: Optional[int]
    artifact_hash: Optional[str]
    is_malicious: bool
    description: Optional[str]
    artifact_metadata: Optional[dict]
    discovered_at: Optional[datetime]
    created_at: datetime

    class Config:
        from_attributes = True


class SessionListResponse(BaseModel):
    """List of analysis sessions."""
    sessions: List[MalwareSessionResponse]
    total: int


# ============================================================================
# Endpoints
# ============================================================================

@router.post("/analyze", response_model=MalwareSessionResponse, status_code=status.HTTP_201_CREATED)
async def analyze_binary(
    file: UploadFile = File(...),
    project_id: Optional[int] = Form(None),
    enable_api_hooks: bool = Form(True),
    enable_network_monitoring: bool = Form(True),
    enable_filesystem_monitoring: bool = Form(True),
    enable_registry_monitoring: bool = Form(True),
    enable_crypto_monitoring: bool = Form(True),
    enable_anti_evasion: bool = Form(True),
    timeout_seconds: int = Form(300),
    network_mode: str = Form("isolated"),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    Start malware analysis on uploaded binary.

    This endpoint:
    1. Saves the uploaded binary
    2. Creates analysis session in database
    3. Starts asynchronous Frida analysis
    4. Returns session info immediately

    Use WebSocket or polling to get real-time updates.
    """
    try:
        # Save uploaded file with sanitized filename to prevent path traversal
        import tempfile
        import os

        temp_dir = tempfile.mkdtemp(prefix="malware_")
        safe_filename = sanitize_filename(file.filename, preserve_extension=True)
        binary_path = os.path.join(temp_dir, safe_filename)

        with open(binary_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"Binary uploaded: {file.filename} -> {safe_filename} ({len(content)} bytes)")

        # Calculate hash
        import hashlib
        sha256 = hashlib.sha256(content).hexdigest()
        md5 = hashlib.md5(content).hexdigest()

        # Detect platform
        platform = "windows" if content[:2] == b'MZ' else "linux"

        # Create database session
        session_id = f"mal_{sha256[:12]}"
        db_session = MalwareAnalysisSession(
            session_id=session_id,
            user_id=current_user.id,
            project_id=project_id,
            binary_name=file.filename,
            binary_hash_sha256=sha256,
            binary_hash_md5=md5,
            binary_size=len(content),
            binary_path=binary_path,
            platform=platform,
            architecture="unknown",  # Will be detected
            status="created",
        )
        db.add(db_session)
        db.commit()
        db.refresh(db_session)

        logger.info(f"Created malware analysis session: {session_id}")

        # Start analysis asynchronously (don't await)
        # In production, this would be a background task
        frida_config = FridaConfig(
            enable_api_hooks=enable_api_hooks,
            enable_network_monitoring=enable_network_monitoring,
            enable_filesystem_monitoring=enable_filesystem_monitoring,
            enable_registry_monitoring=enable_registry_monitoring,
            enable_crypto_monitoring=enable_crypto_monitoring,
            enable_anti_evasion=enable_anti_evasion,
        )

        sandbox_config = SandboxConfig(
            platform=SandboxPlatform.WINDOWS_WINE if platform == "windows" else SandboxPlatform.LINUX,
            network_mode=NetworkMode[network_mode.upper()],
            timeout_seconds=timeout_seconds,
        )

        # Note: In production, use BackgroundTasks or Celery
        # For now, we just mark it as queued
        db_session.status = "queued"
        db.commit()
        db.refresh(db_session)

        return MalwareSessionResponse.from_orm(db_session)

    except Exception as e:
        logger.error(f"Failed to start malware analysis: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to start analysis: {str(e)}"
        )


@router.get("/sessions", response_model=SessionListResponse)
async def list_sessions(
    skip: int = 0,
    limit: int = 50,
    status: Optional[str] = None,
    platform: Optional[str] = None,
    is_malicious: Optional[bool] = None,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """List all malware analysis sessions for current user."""
    query = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.user_id == current_user.id
    )

    if status:
        query = query.filter(MalwareAnalysisSession.status == status)
    if platform:
        query = query.filter(MalwareAnalysisSession.platform == platform)
    if is_malicious is not None:
        query = query.filter(MalwareAnalysisSession.is_malicious == is_malicious)

    total = query.count()
    sessions = query.order_by(MalwareAnalysisSession.created_at.desc()).offset(skip).limit(limit).all()

    return SessionListResponse(
        sessions=[MalwareSessionResponse.from_orm(s) for s in sessions],
        total=total
    )


@router.get("/sessions/{session_id}", response_model=MalwareSessionResponse)
async def get_session(
    session_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get detailed information about a malware analysis session."""
    session = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.session_id == session_id,
        MalwareAnalysisSession.user_id == current_user.id
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )

    return MalwareSessionResponse.from_orm(session)


@router.post("/sessions/{session_id}/stop")
async def stop_session(
    session_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Stop a running malware analysis session."""
    session = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.session_id == session_id,
        MalwareAnalysisSession.user_id == current_user.id
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )

    if session.status not in ["running", "queued"]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot stop session in status: {session.status}"
        )

    # Stop the analysis
    await frida_service.stop_session(session_id)

    session.status = "stopped"
    session.completed_at = datetime.now()
    db.commit()

    return {"status": "stopped", "session_id": session_id}


@router.delete("/sessions/{session_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_session(
    session_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Delete a malware analysis session and all associated data."""
    session = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.session_id == session_id,
        MalwareAnalysisSession.user_id == current_user.id
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )

    # Delete session (cascade will delete behaviors and artifacts)
    db.delete(session)
    db.commit()

    # Cleanup files
    import shutil
    if session.binary_path:
        try:
            temp_dir = os.path.dirname(session.binary_path)
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
        except Exception as e:
            logger.warning(f"Failed to cleanup files for {session_id}: {e}")

    return None


@router.get("/sessions/{session_id}/behavior", response_model=List[RuntimeBehaviorResponse])
async def get_session_behavior(
    session_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get runtime behavior captured during analysis."""
    session = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.session_id == session_id,
        MalwareAnalysisSession.user_id == current_user.id
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )

    behaviors = db.query(RuntimeBehavior).filter(
        RuntimeBehavior.session_id == session_id
    ).all()

    return [RuntimeBehaviorResponse.from_orm(b) for b in behaviors]


@router.get("/sessions/{session_id}/artifacts", response_model=List[MalwareArtifactResponse])
async def get_session_artifacts(
    session_id: str,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get artifacts discovered during analysis."""
    session = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.session_id == session_id,
        MalwareAnalysisSession.user_id == current_user.id
    ).first()

    if not session:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Session {session_id} not found"
        )

    artifacts = db.query(MalwareArtifact).filter(
        MalwareArtifact.session_id == session_id
    ).all()

    return [MalwareArtifactResponse.from_orm(a) for a in artifacts]


@router.websocket("/sessions/{session_id}/stream")
async def stream_analysis(
    websocket: WebSocket,
    session_id: str,
):
    """
    WebSocket endpoint for real-time analysis progress.

    Streams updates including:
    - Phase changes
    - Progress updates
    - Behavior discoveries
    - Completion status
    """
    await websocket.accept()

    try:
        # Send initial connection message
        await websocket.send_json({
            "type": "connected",
            "session_id": session_id,
            "message": "Connected to analysis stream"
        })

        # Get analysis result from service
        result = frida_service.get_session(session_id)
        if not result:
            await websocket.send_json({
                "type": "error",
                "error": f"Session {session_id} not found in service"
            })
            await websocket.close()
            return

        # Stream updates
        while result.status in ["running", "analyzing"]:
            # Send current status
            await websocket.send_json({
                "type": "progress",
                "session_id": session_id,
                "phase": result.phase.value if result.phase else "unknown",
                "progress": result.progress,
                "status": result.status
            })

            # Wait before next update
            import asyncio
            await asyncio.sleep(1)

            # Refresh result
            result = frida_service.get_session(session_id)
            if not result:
                break

        # Send final status
        await websocket.send_json({
            "type": "complete",
            "session_id": session_id,
            "status": result.status if result else "unknown",
            "malware_profile": {
                "is_malicious": result.malware_profile.is_malicious if result else False,
                "threat_score": result.malware_profile.threat_score if result else 0
            } if result else None
        })

    except WebSocketDisconnect:
        logger.info(f"WebSocket disconnected for session {session_id}")
    except Exception as e:
        logger.error(f"WebSocket error for session {session_id}: {e}")
        try:
            await websocket.send_json({"type": "error", "error": str(e)})
        except:
            pass
    finally:
        try:
            await websocket.close()
        except:
            pass


@router.get("/stats")
async def get_stats(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """Get malware analysis statistics for current user."""
    total_sessions = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.user_id == current_user.id
    ).count()

    malicious_count = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.user_id == current_user.id,
        MalwareAnalysisSession.is_malicious == True
    ).count()

    running_count = db.query(MalwareAnalysisSession).filter(
        MalwareAnalysisSession.user_id == current_user.id,
        MalwareAnalysisSession.status == "running"
    ).count()

    # Get malware families distribution
    from sqlalchemy import func
    families = db.query(
        MalwareAnalysisSession.malware_family,
        func.count(MalwareAnalysisSession.id).label('count')
    ).filter(
        MalwareAnalysisSession.user_id == current_user.id,
        MalwareAnalysisSession.malware_family.isnot(None)
    ).group_by(MalwareAnalysisSession.malware_family).all()

    return {
        "total_sessions": total_sessions,
        "malicious_count": malicious_count,
        "benign_count": total_sessions - malicious_count,
        "running_count": running_count,
        "malware_families": [{"family": f[0], "count": f[1]} for f in families]
    }


@router.post("/analyze/agentic", status_code=status.HTTP_201_CREATED)
async def analyze_with_agentic_system(
    file: UploadFile = File(...),
    project_id: Optional[int] = Form(None),
    timeout_seconds: int = Form(300),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    Perform autonomous agentic analysis with 6 specialized agents.

    This endpoint uses the multi-agent system for comprehensive analysis:
    - Orchestrator Agent: Coordinates workflow
    - Static Analysis Agent: Binary structure and signatures
    - Dynamic Analysis Agent: Runtime monitoring
    - Behavioral Agent: Pattern recognition and MITRE mapping
    - Unpacking Agent: Handles packed samples
    - Evasion Detection Agent: Anti-analysis techniques

    The system adapts the analysis strategy based on findings.
    """
    try:
        # Save uploaded file with sanitized filename to prevent path traversal
        import tempfile
        import os

        temp_dir = tempfile.mkdtemp(prefix="agentic_malware_")
        safe_filename = sanitize_filename(file.filename, preserve_extension=True)
        binary_path = os.path.join(temp_dir, safe_filename)

        with open(binary_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"[AGENTIC] Binary uploaded: {file.filename} -> {safe_filename} ({len(content)} bytes)")

        # Calculate hash
        import hashlib
        sha256 = hashlib.sha256(content).hexdigest()
        md5 = hashlib.md5(content).hexdigest()

        # Detect platform
        platform = "windows" if content[:2] == b'MZ' else "linux"

        # Create context for agentic analysis
        context = {
            "binary_path": binary_path,
            "binary_name": file.filename,
            "binary_hash": sha256,
            "platform": platform,
            "architecture": "x64",  # Would be detected
            "file_size": len(content),
            "timeout": timeout_seconds,
            "imports": [],  # Would be extracted
            "sections": [],  # Would be extracted
            "api_calls": [],  # Filled during dynamic analysis
            "network_connections": [],  # Filled during dynamic analysis
            "registry_modified": [],  # Filled during dynamic analysis
            "files_accessed": [],  # Filled during dynamic analysis
            "files_created": [],  # Filled during dynamic analysis
        }

        # Execute agentic analysis
        logger.info(f"[AGENTIC] Starting autonomous analysis for {file.filename}")
        workflow = await agentic_system.analyze(context)

        # Create database session
        session_id = f"agt_{sha256[:12]}"
        db_session = MalwareAnalysisSession(
            session_id=session_id,
            user_id=current_user.id,
            project_id=project_id,
            binary_name=file.filename,
            binary_hash_sha256=sha256,
            binary_hash_md5=md5,
            binary_size=len(content),
            binary_path=binary_path,
            platform=platform,
            architecture="x64",
            status="completed",
            is_malicious=workflow.is_malicious,
            malware_family=workflow.malware_family,
            threat_score=workflow.threat_score,
            confidence_score=workflow.confidence_score,
            severity="critical" if workflow.threat_score > 75 else "high" if workflow.threat_score > 50 else "medium" if workflow.threat_score > 25 else "low",
            started_at=workflow.started_at,
            completed_at=workflow.completed_at
        )
        db.add(db_session)
        db.commit()
        db.refresh(db_session)

        # Get workflow summary
        summary = agentic_system.get_workflow_summary(workflow)

        logger.info(f"[AGENTIC] Analysis complete. Session: {session_id}, Malicious: {workflow.is_malicious}, Threat: {workflow.threat_score}")

        return {
            "session_id": session_id,
            "binary_name": file.filename,
            "binary_hash": sha256,
            "platform": platform,
            "is_malicious": workflow.is_malicious,
            "malware_family": workflow.malware_family,
            "threat_score": workflow.threat_score,
            "confidence_score": workflow.confidence_score,
            "agents_executed": workflow.total_agents_executed,
            "total_execution_time": workflow.total_execution_time,
            "workflow_summary": summary
        }

    except Exception as e:
        logger.error(f"[AGENTIC] Failed to perform analysis: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to perform agentic analysis: {str(e)}"
        )


@router.post("/analyze/integrated", status_code=status.HTTP_201_CREATED)
async def analyze_with_integrated_system(
    file: UploadFile = File(...),
    project_id: Optional[int] = Form(None),
    analysis_type: str = Form("standard"),  # quick, standard, comprehensive
    components: Optional[str] = Form(None),  # Comma-separated: static,dynamic,malware,fuzzing
    timeout_seconds: int = Form(900),
    use_ai: bool = Form(True),
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """
    **UNIFIED INTELLIGENT BINARY ANALYSIS** ðŸ§ 

    The most comprehensive analysis available in VRAgent.
    Combines ALL analysis capabilities with AI-powered intelligence:

    **Analysis Components:**
    - âœ… Static Analysis (SAST)
    - âœ… Dynamic Analysis (Runtime monitoring)
    - âœ… Malware Analysis (6-agent system)
    - âœ… Fuzzing (optional)
    - âœ… Reverse Engineering (optional)
    - âœ… Network Analysis (optional)

    **AI Intelligence:**
    - ðŸ¤– Gemini-powered classification
    - ðŸ¤– Natural language behavior explanation
    - ðŸ¤– Automated remediation recommendations
    - ðŸ¤– Threat actor attribution
    - ðŸ¤– Cross-analysis correlation

    **Analysis Types:**
    - `quick`: 2-5 minutes (static + basic dynamic)
    - `standard`: 10-15 minutes (full malware analysis)
    - `comprehensive`: 30-60 minutes (everything including fuzzing)

    **Components (optional):**
    - Comma-separated list: "static,dynamic,malware,fuzzing,reverse_engineering,network"
    - If not specified, uses defaults based on analysis type
    """
    try:
        # Save uploaded file with sanitized filename to prevent path traversal
        import tempfile
        import os

        temp_dir = tempfile.mkdtemp(prefix="integrated_")
        safe_filename = sanitize_filename(file.filename, preserve_extension=True)
        binary_path = os.path.join(temp_dir, safe_filename)

        with open(binary_path, "wb") as f:
            content = await file.read()
            f.write(content)

        logger.info(f"[INTEGRATED] Starting analysis: {file.filename} -> {safe_filename} ({len(content)} bytes)")

        # Parse analysis type
        try:
            analysis_type_enum = AnalysisType(analysis_type.lower())
        except ValueError:
            analysis_type_enum = AnalysisType.STANDARD

        # Parse components
        component_list = []
        if components:
            for comp in components.split(","):
                comp = comp.strip().lower()
                if comp == "static":
                    component_list.append(AnalysisComponent.STATIC)
                elif comp == "dynamic":
                    component_list.append(AnalysisComponent.DYNAMIC)
                elif comp == "malware":
                    component_list.append(AnalysisComponent.MALWARE)
                elif comp == "fuzzing":
                    component_list.append(AnalysisComponent.FUZZING)
                elif comp == "reverse_engineering":
                    component_list.append(AnalysisComponent.REVERSE_ENGINEERING)
                elif comp == "network":
                    component_list.append(AnalysisComponent.NETWORK)
        else:
            # Default components based on analysis type
            if analysis_type_enum == AnalysisType.QUICK:
                component_list = [AnalysisComponent.STATIC, AnalysisComponent.MALWARE]
            elif analysis_type_enum == AnalysisType.STANDARD:
                component_list = [AnalysisComponent.STATIC, AnalysisComponent.DYNAMIC, AnalysisComponent.MALWARE]
            elif analysis_type_enum == AnalysisType.COMPREHENSIVE:
                component_list = [
                    AnalysisComponent.STATIC,
                    AnalysisComponent.DYNAMIC,
                    AnalysisComponent.MALWARE,
                    AnalysisComponent.FUZZING,
                    AnalysisComponent.REVERSE_ENGINEERING
                ]

        # Create config
        config = IntegratedAnalysisConfig(
            analysis_type=analysis_type_enum,
            components=component_list,
            timeout_seconds=timeout_seconds,
            use_ai_classification=use_ai
        )

        logger.info(f"[INTEGRATED] Config: {analysis_type_enum.value}, components: {[c.value for c in component_list]}")

        # Execute integrated analysis
        result = await integrated_analyzer.analyze(binary_path, file.filename, config)

        # Save to database
        import hashlib
        sha256 = hashlib.sha256(content).hexdigest()
        md5 = hashlib.md5(content).hexdigest()
        platform = "windows" if content[:2] == b'MZ' else "linux"

        session_id = result.session_id
        db_session = MalwareAnalysisSession(
            session_id=session_id,
            user_id=current_user.id,
            project_id=project_id,
            binary_name=file.filename,
            binary_hash_sha256=sha256,
            binary_hash_md5=md5,
            binary_size=len(content),
            binary_path=binary_path,
            platform=platform,
            architecture="x64",
            status="completed",
            is_malicious=result.is_malicious,
            malware_family=result.malware_family,
            threat_score=result.threat_score,
            confidence_score=result.confidence_score,
            severity=result.severity,
            capabilities=result.ai_classification.get("capabilities", []) if result.ai_classification else [],
            mitre_tactics=result.mitre_tactics,
            mitre_techniques=result.mitre_techniques,
            iocs=result.iocs,
            started_at=result.started_at,
            completed_at=result.completed_at
        )
        db.add(db_session)
        db.commit()
        db.refresh(db_session)

        # Get summary
        summary = integrated_analyzer.get_analysis_summary(result)

        logger.info(f"[INTEGRATED] Complete! Malicious: {result.is_malicious}, Threat: {result.threat_score}")

        return {
            "session_id": session_id,
            "binary_name": file.filename,
            "binary_hash": sha256,
            "analysis_type": analysis_type_enum.value,
            "components_executed": [c.value for c in result.component_results.keys()],
            "is_malicious": result.is_malicious,
            "malware_family": result.malware_family,
            "threat_score": result.threat_score,
            "confidence_score": result.confidence_score,
            "severity": result.severity,
            "ai_powered": result.ai_classification is not None,
            "behavior_explanation": result.behavior_explanation,
            "remediation_steps": result.remediation_steps,
            "mitre_tactics": result.mitre_tactics,
            "mitre_techniques": result.mitre_techniques,
            "cross_correlations": len(result.cross_analysis_correlations),
            "total_duration": result.total_duration,
            "summary": summary
        }

    except Exception as e:
        logger.error(f"[INTEGRATED] Analysis failed: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Integrated analysis failed: {str(e)}"
        )
