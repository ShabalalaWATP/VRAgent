"""
Concolic Execution Service for Hybrid Fuzzing.

Concolic (CONCrete + symbOLIC) execution combines concrete execution with
symbolic analysis to systematically explore program paths. This service
integrates with AFL++ to:

1. Select promising inputs from the corpus that are near unexplored branches
2. Execute them with symbolic constraint collection
3. Solve constraints to generate inputs that flip branches
4. Feed new inputs back to AFL++ for further fuzzing

Supported backends:
- angr: Pure Python symbolic execution (primary, cross-platform)
- QSYM: Fast binary-only concolic execution (Linux)
- SymCC: Compile-time instrumentation for symbolic execution (Linux)
"""

from dataclasses import dataclass, field
from typing import Any, AsyncGenerator, Callable, Dict, List, Optional, Set, Tuple
from enum import Enum
import asyncio
import base64
import hashlib
import json
import logging
import os
import shutil
import struct
import tempfile
import time

logger = logging.getLogger(__name__)


class ConcolicBackend(str, Enum):
    """Supported concolic execution backends."""
    ANGR = "angr"
    ANGR_LIGHT = "angr_light"  # Lightweight angr mode
    QSYM = "qsym"
    SYMCC = "symcc"
    AUTO = "auto"


class ConstraintType(str, Enum):
    """Types of symbolic constraints."""
    EQUALITY = "eq"  # x == value
    INEQUALITY = "ne"  # x != value
    LESS_THAN = "lt"  # x < value
    LESS_EQUAL = "le"  # x <= value
    GREATER_THAN = "gt"  # x > value
    GREATER_EQUAL = "ge"  # x >= value
    SIGNED_LT = "slt"  # signed x < value
    SIGNED_GT = "sgt"  # signed x > value


@dataclass
class ConcolicConfig:
    """Configuration for concolic execution."""
    backend: ConcolicBackend = ConcolicBackend.AUTO
    target_path: str = ""
    target_args: str = "@@"
    timeout_seconds: int = 60
    # Constraint solving
    max_constraints: int = 1000
    max_solver_time_ms: int = 5000
    solver: str = "z3"  # z3, bitwuzla
    # Execution options
    max_states: int = 100  # Max active states
    max_step_count: int = 100000  # Max steps per input
    prioritize_new_coverage: bool = True
    # QSYM-specific
    qsym_path: Optional[str] = None
    pin_path: Optional[str] = None
    # SymCC-specific
    symcc_target_path: Optional[str] = None  # Pre-instrumented binary
    symcc_runtime_path: Optional[str] = None
    # Output
    output_dir: str = ""
    telemetry_dir: Optional[str] = None
    # Integration
    afl_queue_dir: Optional[str] = None
    afl_bitmap_path: Optional[str] = None


@dataclass
class SymbolicConstraint:
    """A symbolic constraint from execution."""
    constraint_id: int
    branch_address: int
    constraint_type: ConstraintType
    symbolic_expr: str  # SMT-LIB format or readable format
    concrete_value: bytes  # Current concrete value
    input_bytes_involved: List[int]  # Offsets in input
    negated: bool = False  # Whether to negate for new path
    solver_time_ms: float = 0.0
    solvable: Optional[bool] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "constraint_id": self.constraint_id,
            "branch_address": hex(self.branch_address),
            "constraint_type": self.constraint_type.value,
            "symbolic_expr": self.symbolic_expr[:200],  # Truncate for display
            "concrete_value": base64.b64encode(self.concrete_value).decode(),
            "input_bytes_involved": self.input_bytes_involved[:20],
            "negated": self.negated,
            "solver_time_ms": self.solver_time_ms,
            "solvable": self.solvable,
        }


@dataclass
class GeneratedInput:
    """An input generated by solving constraints."""
    input_id: str
    input_data: bytes
    source_input_id: str
    constraint_solved: int  # Which constraint was negated
    target_branch: int  # Branch address we're trying to flip
    expected_new_coverage: bool
    solver_time_ms: float

    def to_dict(self) -> Dict[str, Any]:
        return {
            "input_id": self.input_id,
            "input_data_b64": base64.b64encode(self.input_data).decode(),
            "input_size": len(self.input_data),
            "source_input_id": self.source_input_id,
            "constraint_solved": self.constraint_solved,
            "target_branch": hex(self.target_branch),
            "expected_new_coverage": self.expected_new_coverage,
            "solver_time_ms": self.solver_time_ms,
        }


@dataclass
class ExecutionPath:
    """A single execution path explored."""
    path_id: str
    branch_count: int
    constraint_count: int
    termination_reason: str  # completed, timeout, error, state_limit
    final_address: int
    coverage_bitmap_hash: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "path_id": self.path_id,
            "branch_count": self.branch_count,
            "constraint_count": self.constraint_count,
            "termination_reason": self.termination_reason,
            "final_address": hex(self.final_address),
        }


@dataclass
class ConcolicResult:
    """Result of concolic execution on a single input."""
    input_id: str
    input_path: str
    input_size: int
    input_hash: str
    execution_time_ms: float
    # Constraint analysis
    constraints_collected: int
    constraints_solved: int
    constraints_unsolvable: int
    solver_time_total_ms: float
    # Generated inputs
    new_inputs_generated: int
    generated_inputs: List[GeneratedInput]
    # Coverage
    new_coverage_found: bool
    branches_explored: int
    paths_explored: List[ExecutionPath]
    # Integration
    inputs_fed_to_afl: int
    # Metadata
    backend_used: str
    errors: List[str] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "input_id": self.input_id,
            "input_path": self.input_path,
            "input_size": self.input_size,
            "input_hash": self.input_hash,
            "execution_time_ms": self.execution_time_ms,
            "constraints_collected": self.constraints_collected,
            "constraints_solved": self.constraints_solved,
            "constraints_unsolvable": self.constraints_unsolvable,
            "solver_time_total_ms": self.solver_time_total_ms,
            "new_inputs_generated": self.new_inputs_generated,
            "generated_inputs": [g.to_dict() for g in self.generated_inputs[:10]],
            "new_coverage_found": self.new_coverage_found,
            "branches_explored": self.branches_explored,
            "paths_explored": [p.to_dict() for p in self.paths_explored[:10]],
            "inputs_fed_to_afl": self.inputs_fed_to_afl,
            "backend_used": self.backend_used,
            "errors": self.errors,
            "warnings": self.warnings,
        }


def _find_tool(name: str, env_var: Optional[str] = None) -> Optional[str]:
    """Find tool binary in common locations."""
    if env_var:
        path = os.environ.get(env_var)
        if path and os.path.isfile(path):
            return path

    search_paths = [
        "/usr/local/bin",
        "/usr/bin",
        "/opt",
        os.path.expanduser("~/.local/bin"),
    ]

    for base in search_paths:
        full_path = os.path.join(base, name)
        if os.path.isfile(full_path) and os.access(full_path, os.X_OK):
            return full_path

    return shutil.which(name)


def _compute_file_hash(path: str) -> str:
    """Compute SHA256 hash of file."""
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()[:16]


def _generate_input_id(data: bytes) -> str:
    """Generate unique ID for input."""
    h = hashlib.sha256(data).hexdigest()[:12]
    return f"concolic_{h}"


class ConcolicExecutionService:
    """
    QSYM-style concolic execution service for hybrid fuzzing.

    Integrates with AFL++ to:
    1. Select promising inputs from corpus based on coverage/novelty
    2. Execute with concolic tracing to collect path constraints
    3. Solve constraints for inputs that flip branches
    4. Feed new inputs back to AFL++ corpus

    Example usage:
        config = ConcolicConfig(
            target_path="/path/to/binary",
            afl_queue_dir="/fuzzing/output/queue",
        )
        service = ConcolicExecutionService(config)

        # Analyze a single input
        result = await service.analyze_input("/path/to/input.bin")
        print(f"Generated {result.new_inputs_generated} new inputs")

        # Feed to AFL++
        fed = await service.feed_to_afl(result.generated_inputs)
        print(f"Fed {fed} inputs to AFL++")
    """

    def __init__(self, config: ConcolicConfig):
        self.config = config
        self._running = False
        self._stop_requested = False
        self.stats: Dict[str, Any] = {
            "inputs_analyzed": 0,
            "constraints_collected": 0,
            "constraints_solved": 0,
            "inputs_generated": 0,
            "inputs_fed_to_afl": 0,
            "solver_time_total_ms": 0.0,
            "coverage_contributions": 0,
        }
        self._backend: Optional[str] = None
        self._angr_project = None
        self._coverage_bitmap: Optional[bytes] = None

    def _select_backend(self) -> str:
        """Select the best available backend."""
        if self.config.backend != ConcolicBackend.AUTO:
            return self.config.backend.value

        # Check QSYM (fastest for binary-only)
        qsym_path = self.config.qsym_path or _find_tool("qsym")
        if qsym_path and os.name != "nt":
            return ConcolicBackend.QSYM.value

        # Check SymCC (if instrumented binary available)
        if self.config.symcc_target_path and os.path.isfile(self.config.symcc_target_path):
            return ConcolicBackend.SYMCC.value

        # Fall back to angr
        try:
            import angr
            return ConcolicBackend.ANGR_LIGHT.value
        except ImportError:
            pass

        return ConcolicBackend.ANGR_LIGHT.value  # Will error if not installed

    async def start(self) -> AsyncGenerator[Dict[str, Any], None]:
        """
        Start concolic execution service.

        Yields status updates during operation.
        """
        self._running = True
        self._stop_requested = False
        self._backend = self._select_backend()

        yield {
            "type": "service_started",
            "backend": self._backend,
            "config": {
                "target": self.config.target_path,
                "max_constraints": self.config.max_constraints,
            }
        }

        while self._running and not self._stop_requested:
            await asyncio.sleep(1)
            yield {
                "type": "status",
                "stats": self.stats.copy(),
            }

        yield {
            "type": "service_stopped",
            "stats": self.stats.copy(),
        }

    async def stop(self) -> None:
        """Stop the service gracefully."""
        self._stop_requested = True
        self._running = False

    async def analyze_input(
        self,
        input_path: str,
        coverage_bitmap: Optional[bytes] = None,
        target_path: Optional[str] = None,
        target_args: Optional[str] = None,
    ) -> ConcolicResult:
        """
        Perform concolic execution on a single input.

        Args:
            input_path: Path to input file
            coverage_bitmap: Current AFL++ coverage for prioritization
            target_path: Override target path
            target_args: Override target args

        Returns:
            ConcolicResult with generated inputs
        """
        start_time = time.time()

        target = target_path or self.config.target_path
        args = target_args or self.config.target_args

        # Validate
        if not os.path.isfile(input_path):
            return ConcolicResult(
                input_id="",
                input_path=input_path,
                input_size=0,
                input_hash="",
                execution_time_ms=0,
                constraints_collected=0,
                constraints_solved=0,
                constraints_unsolvable=0,
                solver_time_total_ms=0,
                new_inputs_generated=0,
                generated_inputs=[],
                new_coverage_found=False,
                branches_explored=0,
                paths_explored=[],
                inputs_fed_to_afl=0,
                backend_used="none",
                errors=[f"Input file not found: {input_path}"],
            )

        if not os.path.isfile(target):
            return ConcolicResult(
                input_id="",
                input_path=input_path,
                input_size=0,
                input_hash="",
                execution_time_ms=0,
                constraints_collected=0,
                constraints_solved=0,
                constraints_unsolvable=0,
                solver_time_total_ms=0,
                new_inputs_generated=0,
                generated_inputs=[],
                new_coverage_found=False,
                branches_explored=0,
                paths_explored=[],
                inputs_fed_to_afl=0,
                backend_used="none",
                errors=[f"Target not found: {target}"],
            )

        # Read input
        with open(input_path, "rb") as f:
            input_data = f.read()

        input_size = len(input_data)
        input_hash = _compute_file_hash(input_path)
        input_id = f"{os.path.basename(input_path)}_{input_hash}"

        if coverage_bitmap:
            self._coverage_bitmap = coverage_bitmap

        # Select backend and run
        backend = self._select_backend()

        if backend == ConcolicBackend.ANGR.value or backend == ConcolicBackend.ANGR_LIGHT.value:
            result = await self._analyze_with_angr(
                input_path, input_data, target, args,
                input_id, input_size, input_hash,
                light_mode=(backend == ConcolicBackend.ANGR_LIGHT.value)
            )
        elif backend == ConcolicBackend.QSYM.value:
            result = await self._analyze_with_qsym(
                input_path, input_data, target, args,
                input_id, input_size, input_hash
            )
        elif backend == ConcolicBackend.SYMCC.value:
            result = await self._analyze_with_symcc(
                input_path, input_data, target, args,
                input_id, input_size, input_hash
            )
        else:
            # Fallback to simulated analysis
            result = await self._analyze_simulated(
                input_path, input_data, target, args,
                input_id, input_size, input_hash
            )

        result.execution_time_ms = (time.time() - start_time) * 1000
        result.backend_used = backend

        # Update stats
        self.stats["inputs_analyzed"] += 1
        self.stats["constraints_collected"] += result.constraints_collected
        self.stats["constraints_solved"] += result.constraints_solved
        self.stats["inputs_generated"] += result.new_inputs_generated
        self.stats["solver_time_total_ms"] += result.solver_time_total_ms

        return result

    async def _analyze_with_angr(
        self,
        input_path: str,
        input_data: bytes,
        target: str,
        args: str,
        input_id: str,
        input_size: int,
        input_hash: str,
        light_mode: bool = True,
    ) -> ConcolicResult:
        """Analyze using angr symbolic execution."""
        try:
            import angr
            import claripy
        except ImportError:
            return ConcolicResult(
                input_id=input_id,
                input_path=input_path,
                input_size=input_size,
                input_hash=input_hash,
                execution_time_ms=0,
                constraints_collected=0,
                constraints_solved=0,
                constraints_unsolvable=0,
                solver_time_total_ms=0,
                new_inputs_generated=0,
                generated_inputs=[],
                new_coverage_found=False,
                branches_explored=0,
                paths_explored=[],
                inputs_fed_to_afl=0,
                backend_used="angr",
                errors=["angr not installed. Run: pip install angr"],
            )

        constraints_collected = 0
        constraints_solved = 0
        constraints_unsolvable = 0
        solver_time_total = 0.0
        generated_inputs: List[GeneratedInput] = []
        paths_explored: List[ExecutionPath] = []
        errors: List[str] = []
        warnings: List[str] = []

        try:
            # Create angr project
            proj = angr.Project(target, auto_load_libs=False)

            # Create symbolic input
            symbolic_input = claripy.BVS("input", input_size * 8)

            # Create initial state
            if "@@" in args:
                # File-based input
                with tempfile.NamedTemporaryFile(delete=False, suffix=".sym") as tf:
                    tf.write(input_data)
                    sym_file = tf.name

                state = proj.factory.full_init_state(
                    args=[target] + args.replace("@@", sym_file).split(),
                    add_options=angr.options.unicorn if not light_mode else set(),
                )

                # Make file content symbolic
                simfile = angr.SimFile(sym_file, content=symbolic_input)
                state.fs.insert(sym_file, simfile)
            else:
                # Stdin-based input
                state = proj.factory.full_init_state(
                    args=[target] + args.split() if args else [target],
                    stdin=angr.SimFile("/dev/stdin", content=symbolic_input),
                    add_options=angr.options.unicorn if not light_mode else set(),
                )

            # Configure for lightweight analysis
            if light_mode:
                state.options.add(angr.options.LAZY_SOLVES)
                state.options.discard(angr.options.TRACK_CONSTRAINTS)

            # Create simulation manager
            simgr = proj.factory.simulation_manager(state)

            # Explore with limits
            step_count = 0
            max_steps = self.config.max_step_count if not light_mode else 10000
            branch_points: Set[int] = set()

            while simgr.active and step_count < max_steps:
                if self._stop_requested:
                    break

                simgr.step()
                step_count += 1

                # Track branch points
                for s in simgr.active:
                    if s.history.jump_guard is not None:
                        branch_points.add(s.addr)
                        constraints_collected += 1

                # Limit active states
                if len(simgr.active) > self.config.max_states:
                    simgr.active = simgr.active[:self.config.max_states]

                # Move deadended/errored states
                simgr.move(from_stash='deadended', to_stash='_deadended')
                simgr.move(from_stash='errored', to_stash='_errored')

            # Generate inputs from interesting states
            all_states = simgr.active + simgr.stashes.get('_deadended', [])

            for state in all_states[:20]:  # Limit to prevent explosion
                try:
                    solver_start = time.time()

                    # Try to get concrete input
                    if state.solver.satisfiable():
                        concrete = state.solver.eval(symbolic_input, cast_to=bytes)
                        solver_time = (time.time() - solver_start) * 1000
                        solver_time_total += solver_time

                        if concrete != input_data:
                            gen_input = GeneratedInput(
                                input_id=_generate_input_id(concrete),
                                input_data=concrete,
                                source_input_id=input_id,
                                constraint_solved=constraints_solved,
                                target_branch=state.addr,
                                expected_new_coverage=True,
                                solver_time_ms=solver_time,
                            )
                            generated_inputs.append(gen_input)
                            constraints_solved += 1
                    else:
                        constraints_unsolvable += 1

                except Exception as e:
                    constraints_unsolvable += 1
                    if len(warnings) < 10:
                        warnings.append(f"Solver error: {str(e)[:100]}")

            # Create path records
            for i, state in enumerate(all_states[:10]):
                paths_explored.append(ExecutionPath(
                    path_id=f"path_{i}",
                    branch_count=len(branch_points),
                    constraint_count=len(state.solver.constraints) if hasattr(state.solver, 'constraints') else 0,
                    termination_reason="completed" if state in simgr.stashes.get('_deadended', []) else "active",
                    final_address=state.addr,
                ))

        except Exception as e:
            errors.append(f"angr analysis error: {str(e)}")
            logger.exception("angr analysis failed")

        return ConcolicResult(
            input_id=input_id,
            input_path=input_path,
            input_size=input_size,
            input_hash=input_hash,
            execution_time_ms=0,
            constraints_collected=constraints_collected,
            constraints_solved=constraints_solved,
            constraints_unsolvable=constraints_unsolvable,
            solver_time_total_ms=solver_time_total,
            new_inputs_generated=len(generated_inputs),
            generated_inputs=generated_inputs,
            new_coverage_found=len(generated_inputs) > 0,
            branches_explored=len(set(p.final_address for p in paths_explored)),
            paths_explored=paths_explored,
            inputs_fed_to_afl=0,
            backend_used="angr",
            errors=errors,
            warnings=warnings,
        )

    async def _analyze_with_qsym(
        self,
        input_path: str,
        input_data: bytes,
        target: str,
        args: str,
        input_id: str,
        input_size: int,
        input_hash: str,
    ) -> ConcolicResult:
        """Analyze using QSYM (fast binary-only concolic execution)."""
        qsym_path = self.config.qsym_path or _find_tool("qsym")

        if not qsym_path:
            return ConcolicResult(
                input_id=input_id,
                input_path=input_path,
                input_size=input_size,
                input_hash=input_hash,
                execution_time_ms=0,
                constraints_collected=0,
                constraints_solved=0,
                constraints_unsolvable=0,
                solver_time_total_ms=0,
                new_inputs_generated=0,
                generated_inputs=[],
                new_coverage_found=False,
                branches_explored=0,
                paths_explored=[],
                inputs_fed_to_afl=0,
                backend_used="qsym",
                errors=["QSYM not found. Install from: https://github.com/sslab-gatech/qsym"],
            )

        generated_inputs: List[GeneratedInput] = []
        errors: List[str] = []
        warnings: List[str] = []

        # Create output directory
        with tempfile.TemporaryDirectory() as output_dir:
            # Build QSYM command
            cmd = [
                qsym_path,
                "-o", output_dir,
                "-i", input_path,
            ]

            if "@@" in args:
                cmd.extend(["--", target, args.replace("@@", input_path)])
            else:
                cmd.extend(["--", target])
                if args:
                    cmd.extend(args.split())

            try:
                proc = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                )

                stdout, stderr = await asyncio.wait_for(
                    proc.communicate(),
                    timeout=self.config.timeout_seconds,
                )

                # Parse QSYM output
                # QSYM generates new inputs in output_dir
                for filename in os.listdir(output_dir):
                    filepath = os.path.join(output_dir, filename)
                    if os.path.isfile(filepath):
                        with open(filepath, "rb") as f:
                            new_data = f.read()

                        if new_data != input_data:
                            generated_inputs.append(GeneratedInput(
                                input_id=_generate_input_id(new_data),
                                input_data=new_data,
                                source_input_id=input_id,
                                constraint_solved=len(generated_inputs),
                                target_branch=0,
                                expected_new_coverage=True,
                                solver_time_ms=0,
                            ))

            except asyncio.TimeoutError:
                warnings.append("QSYM execution timed out")
            except Exception as e:
                errors.append(f"QSYM error: {str(e)}")

        return ConcolicResult(
            input_id=input_id,
            input_path=input_path,
            input_size=input_size,
            input_hash=input_hash,
            execution_time_ms=0,
            constraints_collected=len(generated_inputs),
            constraints_solved=len(generated_inputs),
            constraints_unsolvable=0,
            solver_time_total_ms=0,
            new_inputs_generated=len(generated_inputs),
            generated_inputs=generated_inputs,
            new_coverage_found=len(generated_inputs) > 0,
            branches_explored=len(generated_inputs),
            paths_explored=[],
            inputs_fed_to_afl=0,
            backend_used="qsym",
            errors=errors,
            warnings=warnings,
        )

    async def _analyze_with_symcc(
        self,
        input_path: str,
        input_data: bytes,
        target: str,
        args: str,
        input_id: str,
        input_size: int,
        input_hash: str,
    ) -> ConcolicResult:
        """Analyze using SymCC (compile-time instrumented concolic execution)."""
        symcc_target = self.config.symcc_target_path

        if not symcc_target or not os.path.isfile(symcc_target):
            return ConcolicResult(
                input_id=input_id,
                input_path=input_path,
                input_size=input_size,
                input_hash=input_hash,
                execution_time_ms=0,
                constraints_collected=0,
                constraints_solved=0,
                constraints_unsolvable=0,
                solver_time_total_ms=0,
                new_inputs_generated=0,
                generated_inputs=[],
                new_coverage_found=False,
                branches_explored=0,
                paths_explored=[],
                inputs_fed_to_afl=0,
                backend_used="symcc",
                errors=["SymCC instrumented binary not found. Build target with symcc compiler."],
            )

        generated_inputs: List[GeneratedInput] = []
        errors: List[str] = []
        warnings: List[str] = []

        # Create output directory
        with tempfile.TemporaryDirectory() as output_dir:
            env = os.environ.copy()
            env["SYMCC_OUTPUT_DIR"] = output_dir

            # Build command
            if "@@" in args:
                cmd = [symcc_target] + args.replace("@@", input_path).split()
            else:
                cmd = [symcc_target] + (args.split() if args else [])

            try:
                proc = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdin=asyncio.subprocess.PIPE if "@@" not in args else None,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    env=env,
                )

                stdin_data = input_data if "@@" not in args else None

                stdout, stderr = await asyncio.wait_for(
                    proc.communicate(input=stdin_data),
                    timeout=self.config.timeout_seconds,
                )

                # Parse SymCC output
                for filename in os.listdir(output_dir):
                    filepath = os.path.join(output_dir, filename)
                    if os.path.isfile(filepath):
                        with open(filepath, "rb") as f:
                            new_data = f.read()

                        if new_data != input_data:
                            generated_inputs.append(GeneratedInput(
                                input_id=_generate_input_id(new_data),
                                input_data=new_data,
                                source_input_id=input_id,
                                constraint_solved=len(generated_inputs),
                                target_branch=0,
                                expected_new_coverage=True,
                                solver_time_ms=0,
                            ))

            except asyncio.TimeoutError:
                warnings.append("SymCC execution timed out")
            except Exception as e:
                errors.append(f"SymCC error: {str(e)}")

        return ConcolicResult(
            input_id=input_id,
            input_path=input_path,
            input_size=input_size,
            input_hash=input_hash,
            execution_time_ms=0,
            constraints_collected=len(generated_inputs),
            constraints_solved=len(generated_inputs),
            constraints_unsolvable=0,
            solver_time_total_ms=0,
            new_inputs_generated=len(generated_inputs),
            generated_inputs=generated_inputs,
            new_coverage_found=len(generated_inputs) > 0,
            branches_explored=len(generated_inputs),
            paths_explored=[],
            inputs_fed_to_afl=0,
            backend_used="symcc",
            errors=errors,
            warnings=warnings,
        )

    async def _analyze_simulated(
        self,
        input_path: str,
        input_data: bytes,
        target: str,
        args: str,
        input_id: str,
        input_size: int,
        input_hash: str,
    ) -> ConcolicResult:
        """
        Simulated concolic analysis using heuristics.

        Fallback when no symbolic execution backend is available.
        Generates mutations based on common patterns.
        """
        warnings = [
            "Using simulated concolic analysis (no backend available)",
            "Install angr for real symbolic execution: pip install angr",
        ]

        generated_inputs: List[GeneratedInput] = []

        # Generate mutations at interesting positions
        interesting_positions = []

        # First few bytes (often magic/length)
        for i in range(min(8, input_size)):
            interesting_positions.append(i)

        # Find potential comparison points
        for i in range(input_size - 3):
            val = struct.unpack("<I", input_data[i:i+4])[0] if i + 4 <= input_size else 0
            # Look for small values that might be lengths/counts
            if 0 < val < 1000:
                interesting_positions.append(i)
            # Look for potential magic values
            if val in [0x464c457f, 0x504b0304, 0x7f454c46]:  # ELF, ZIP magic
                interesting_positions.append(i)

        # Generate mutations
        for pos in interesting_positions[:10]:
            if pos >= input_size:
                continue

            # Flip bits
            mutated = bytearray(input_data)
            mutated[pos] ^= 0xff

            generated_inputs.append(GeneratedInput(
                input_id=_generate_input_id(bytes(mutated)),
                input_data=bytes(mutated),
                source_input_id=input_id,
                constraint_solved=len(generated_inputs),
                target_branch=0,
                expected_new_coverage=True,
                solver_time_ms=0,
            ))

            # Boundary values
            for val in [0, 0xff, 0x7f, 0x80]:
                mutated = bytearray(input_data)
                mutated[pos] = val
                generated_inputs.append(GeneratedInput(
                    input_id=_generate_input_id(bytes(mutated)),
                    input_data=bytes(mutated),
                    source_input_id=input_id,
                    constraint_solved=len(generated_inputs),
                    target_branch=0,
                    expected_new_coverage=True,
                    solver_time_ms=0,
                ))

        # Deduplicate
        seen: Set[str] = {input_hash}
        unique_inputs: List[GeneratedInput] = []
        for gi in generated_inputs:
            h = hashlib.sha256(gi.input_data).hexdigest()[:16]
            if h not in seen:
                seen.add(h)
                unique_inputs.append(gi)

        return ConcolicResult(
            input_id=input_id,
            input_path=input_path,
            input_size=input_size,
            input_hash=input_hash,
            execution_time_ms=0,
            constraints_collected=len(interesting_positions),
            constraints_solved=len(unique_inputs),
            constraints_unsolvable=0,
            solver_time_total_ms=0,
            new_inputs_generated=len(unique_inputs),
            generated_inputs=unique_inputs,
            new_coverage_found=len(unique_inputs) > 0,
            branches_explored=len(interesting_positions),
            paths_explored=[],
            inputs_fed_to_afl=0,
            backend_used="simulated",
            warnings=warnings,
        )

    async def batch_analyze(
        self,
        input_paths: List[str],
        max_parallel: int = 2,
        priority_fn: Optional[Callable[[str], float]] = None,
        progress_callback: Optional[Callable[[int, int], None]] = None,
    ) -> AsyncGenerator[ConcolicResult, None]:
        """
        Analyze multiple inputs with optional prioritization.

        Args:
            input_paths: List of input file paths
            max_parallel: Maximum parallel analyses
            priority_fn: Optional function to prioritize inputs (higher = first)
            progress_callback: Optional callback(completed, total)

        Yields:
            ConcolicResult for each input
        """
        # Sort by priority if function provided
        if priority_fn:
            input_paths = sorted(input_paths, key=priority_fn, reverse=True)

        total = len(input_paths)
        completed = 0

        for i in range(0, total, max_parallel):
            batch = input_paths[i:i + max_parallel]
            tasks = [self.analyze_input(path) for path in batch]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            for result in results:
                completed += 1

                if isinstance(result, Exception):
                    yield ConcolicResult(
                        input_id="",
                        input_path="",
                        input_size=0,
                        input_hash="",
                        execution_time_ms=0,
                        constraints_collected=0,
                        constraints_solved=0,
                        constraints_unsolvable=0,
                        solver_time_total_ms=0,
                        new_inputs_generated=0,
                        generated_inputs=[],
                        new_coverage_found=False,
                        branches_explored=0,
                        paths_explored=[],
                        inputs_fed_to_afl=0,
                        backend_used="error",
                        errors=[str(result)],
                    )
                else:
                    yield result

                if progress_callback:
                    progress_callback(completed, total)

    def prioritize_inputs(
        self,
        corpus_dir: str,
        coverage_bitmap: Optional[bytes] = None,
        max_inputs: int = 10,
    ) -> List[str]:
        """
        Select inputs for concolic analysis using QSYM-style prioritization.

        Prioritizes:
        1. Inputs near uncovered branches
        2. Inputs with recent coverage gains
        3. Inputs not recently analyzed

        Args:
            corpus_dir: Directory containing corpus inputs
            coverage_bitmap: Current AFL++ coverage bitmap
            max_inputs: Maximum inputs to select

        Returns:
            List of prioritized input paths
        """
        if not os.path.isdir(corpus_dir):
            return []

        # Get all inputs with metadata
        inputs_with_score: List[Tuple[str, float]] = []

        for filename in os.listdir(corpus_dir):
            filepath = os.path.join(corpus_dir, filename)
            if not os.path.isfile(filepath):
                continue

            # Skip README files
            if filename.lower().startswith("readme"):
                continue

            # Calculate priority score
            score = 1.0

            # Favor smaller inputs (faster to analyze)
            size = os.path.getsize(filepath)
            if size < 1024:
                score += 0.5
            elif size > 10240:
                score -= 0.3

            # Favor recent inputs (more likely to have new coverage)
            mtime = os.path.getmtime(filepath)
            age_hours = (time.time() - mtime) / 3600
            if age_hours < 1:
                score += 0.8
            elif age_hours < 24:
                score += 0.3

            # Parse AFL++ metadata from filename if available
            if ",+" in filename:  # Has coverage gain
                score += 0.5

            inputs_with_score.append((filepath, score))

        # Sort by score and return top N
        inputs_with_score.sort(key=lambda x: x[1], reverse=True)
        return [path for path, _ in inputs_with_score[:max_inputs]]

    async def feed_to_afl(
        self,
        generated_inputs: List[GeneratedInput],
        afl_queue_dir: Optional[str] = None,
    ) -> int:
        """
        Feed generated inputs to AFL++ corpus.

        Args:
            generated_inputs: Inputs from concolic analysis
            afl_queue_dir: Override AFL++ queue directory

        Returns:
            Number of inputs that were added (deduplicated)
        """
        queue_dir = afl_queue_dir or self.config.afl_queue_dir

        if not queue_dir:
            logger.warning("No AFL queue directory configured")
            return 0

        if not os.path.isdir(queue_dir):
            try:
                os.makedirs(queue_dir, exist_ok=True)
            except Exception as e:
                logger.error(f"Failed to create queue directory: {e}")
                return 0

        added = 0
        for gi in generated_inputs:
            # Generate unique filename
            filename = f"id:concolic,src:{gi.source_input_id[:8]},{gi.input_id}"
            filepath = os.path.join(queue_dir, filename)

            # Check if similar input exists (by hash)
            exists = False
            for existing in os.listdir(queue_dir):
                existing_path = os.path.join(queue_dir, existing)
                if os.path.isfile(existing_path):
                    with open(existing_path, "rb") as f:
                        if f.read() == gi.input_data:
                            exists = True
                            break

            if not exists:
                try:
                    with open(filepath, "wb") as f:
                        f.write(gi.input_data)
                    added += 1
                except Exception as e:
                    logger.error(f"Failed to write input: {e}")

        self.stats["inputs_fed_to_afl"] += added
        return added

    def get_status(self) -> Dict[str, Any]:
        """Get current service status and statistics."""
        return {
            "running": self._running,
            "backend": self._backend or self._select_backend(),
            "stats": self.stats.copy(),
            "config": {
                "target": self.config.target_path,
                "max_constraints": self.config.max_constraints,
                "timeout": self.config.timeout_seconds,
            }
        }


# Convenience functions

async def check_concolic_installation() -> Dict[str, Any]:
    """Check availability of concolic execution backends."""
    result = {
        "angr": {"available": False, "version": None},
        "qsym": {"available": False, "path": None},
        "symcc": {"available": False, "path": None},
        "z3": {"available": False, "version": None},
        "recommended": None,
    }

    # Check angr
    try:
        import angr
        result["angr"]["available"] = True
        result["angr"]["version"] = angr.__version__
        result["recommended"] = "angr"
    except ImportError:
        pass

    # Check Z3 (solver)
    try:
        import z3
        result["z3"]["available"] = True
        result["z3"]["version"] = z3.get_version_string()
    except ImportError:
        pass

    # Check QSYM
    qsym_path = _find_tool("qsym")
    if qsym_path:
        result["qsym"]["available"] = True
        result["qsym"]["path"] = qsym_path
        if not result["recommended"]:
            result["recommended"] = "qsym"

    # Check SymCC
    symcc_path = _find_tool("symcc")
    if symcc_path:
        result["symcc"]["available"] = True
        result["symcc"]["path"] = symcc_path
        if not result["recommended"]:
            result["recommended"] = "symcc"

    return result


def detect_best_backend(target_path: str) -> ConcolicBackend:
    """
    Auto-detect the best concolic backend for target.

    Args:
        target_path: Path to target binary

    Returns:
        Recommended ConcolicBackend
    """
    # Check if it's a source file (SymCC works best)
    if target_path.endswith(('.c', '.cpp', '.cc')):
        symcc = _find_tool("symcc")
        if symcc:
            return ConcolicBackend.SYMCC

    # Check if QSYM is available (fastest for binaries)
    if os.name != "nt":  # QSYM is Linux-only
        qsym = _find_tool("qsym")
        if qsym:
            return ConcolicBackend.QSYM

    # Fall back to angr
    try:
        import angr
        return ConcolicBackend.ANGR_LIGHT
    except ImportError:
        pass

    return ConcolicBackend.AUTO
